{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**How to detect 'toxic' comments using Machine Learning techniques**"
      ],
      "metadata": {
        "id": "N087iRta_ELc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics and limitations \n",
        "Let's assume the program could make a mistake in 1 out of 20 cases\n",
        "\n",
        "Metrics used:\n",
        "1. Recall \n",
        "\n",
        "Bad comments ratio\n",
        "\n",
        "If equal to 1, all bad comments were found \n",
        "2. Precision\n",
        "\n",
        "Probability of a found bad comment to be bad\n",
        "\n",
        "We don't want it to be lower than 0.95\n"
      ],
      "metadata": {
        "id": "SyTNCdwYAC7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goals:\n",
        "1. Develop a Binary classificator (input = comment(text); output = )\n",
        "2. Maximize Recall\n",
        "3. Precision >= 0.95"
      ],
      "metadata": {
        "id": "UfL951XqDneb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Composition\n",
        "\n",
        "Dataset used:\n",
        "\n",
        "Russian Language Toxic Comments\n",
        "\n",
        "https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments?resource=download"
      ],
      "metadata": {
        "id": "8WhPCnM8EnJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing useful libraries \n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#divides a text into a list of sentences\n",
        "#by using an unsupervised algorithm to build a model for abbreviation\n",
        "#words, collocations, and words that start sentences.\n",
        "nltk.download('punkt')\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "import sklearn.metrics as skm\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6oL2WmGDhdB",
        "outputId": "abfdafdc-7874-4156-9f5e-0cd3582a5178"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis (EDA) "
      ],
      "metadata": {
        "id": "53-fcYA6f58G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "df = pd.read_csv('labeled.csv', sep=',')"
      ],
      "metadata": {
        "id": "immAnWlWc_-7"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data shape\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0HHud6ldtK9",
        "outputId": "560d1a73-1e1f-4bf8-92d4-91ecedd5ab3d"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14412, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14412 samples and 2 columns"
      ],
      "metadata": {
        "id": "w8ZRv9CLd1dC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Return first 7 rows\n",
        "df.head(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "5uzV70N9d6P-",
        "outputId": "236a8b29-4855-4869-dea4-8faf05a4ac2c"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  toxic\n",
              "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
              "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
              "2                          Собаке - собачья смерть\\n    1.0\n",
              "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
              "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n",
              "5  Для каких стан является эталоном современная с...    1.0\n",
              "6  В шапке были ссылки на инфу по текущему фильму...    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-101d4f6c-d835-41d2-abbd-b1ecdfa42fa9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Для каких стан является эталоном современная с...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>В шапке были ссылки на инфу по текущему фильму...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-101d4f6c-d835-41d2-abbd-b1ecdfa42fa9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-101d4f6c-d835-41d2-abbd-b1ecdfa42fa9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-101d4f6c-d835-41d2-abbd-b1ecdfa42fa9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change data type from float to integer for data in the 'toxic' column\n",
        "df['toxic'] = df['toxic'].apply(int)"
      ],
      "metadata": {
        "id": "lbQ2fmHAekgi"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Result:\n",
        "df.head(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "vAWPk986e9m4",
        "outputId": "bc0e43b4-5214-45d9-e6ff-acd056a7b71f"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  toxic\n",
              "0               Верблюдов-то за что? Дебилы, бл...\\n      1\n",
              "1  Хохлы, это отдушина затюканого россиянина, мол...      1\n",
              "2                          Собаке - собачья смерть\\n      1\n",
              "3  Страницу обнови, дебил. Это тоже не оскорблени...      1\n",
              "4  тебя не убедил 6-страничный пдф в том, что Скр...      1\n",
              "5  Для каких стан является эталоном современная с...      1\n",
              "6  В шапке были ссылки на инфу по текущему фильму...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb77059a-3c88-4aa9-9df9-5d24fe309d02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Собаке - собачья смерть\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Для каких стан является эталоном современная с...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>В шапке были ссылки на инфу по текущему фильму...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb77059a-3c88-4aa9-9df9-5d24fe309d02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb77059a-3c88-4aa9-9df9-5d24fe309d02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb77059a-3c88-4aa9-9df9-5d24fe309d02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution: how many toxic comments in the dataset\n",
        "df['toxic'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRuYx0ghfKhA",
        "outputId": "f83a4fde-1109-4a93-aff7-18b87a67d4fa"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9586\n",
              "1    4826\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are almost twice as many good comments as toxic ones."
      ],
      "metadata": {
        "id": "3MCP32nUfpEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Return first 7 toxic comments\n",
        "for i in df[df['toxic'] == 1]['comment'].head(7):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pl1eg9Oht55",
        "outputId": "6844b7f4-0b33-4146-eac4-1f75e661206a"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Верблюдов-то за что? Дебилы, бл...\n",
            "\n",
            "Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
            "\n",
            "Собаке - собачья смерть\n",
            "\n",
            "Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
            "\n",
            "тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\n",
            "\n",
            "Для каких стан является эталоном современная система здравоохранения РФ? Для Зимбабве? Ты тупой? хохлы\n",
            "\n",
            "УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РАЗВОРУЮТ КАК ВСЕГДА! УЖЕ ТРЕЩИНАМИ ПОШ Л! ТУПЫЕ КИТАЗЫ НЕ МОГУТ НИЧЕГО НОРМАЛЬНО СДЕЛАТЬ!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Return first 7 good comments\n",
        "for i in df[df['toxic'] == 0]['comment'].head(7):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxTS92thiW7u",
        "outputId": "41bf1931-09cd-4bab-a56b-4b241d8408e1"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В шапке были ссылки на инфу по текущему фильму марвел. Эти ссылки были заменены на фразу Репортим брипидора, игнорируем его посты. Если этого недостаточно, чтобы понять, что модератор абсолютный неадекват, и его нужно лишить полномочий, тогда эта борда пробивает абсолютное дно по неадекватности.\n",
            "\n",
            "Почитайте посты у этого автора,может найдете что нибудь полезное. Надеюсь помог) https: pikabu.ru story obyichnyie budni dezsluzhbyi 4932098\n",
            "\n",
            "Про графику было обидно) я так то проходил все серии гта со второй части по пятую, кроме гта 4. И мне не мешала графика ни в одной из частей. На компе у меня было куча видеокарт. Начиная с 32мб RIVA TNT и заканчивая 2Гб 560Ti на которой я спокойно играю который год в танки, гта5, ведьмака3 купил на распродаже и начал проходить. Да, не на ультрах. С пониженными текстурами. И не мешает. Я не понимаю дрочева на графике, требовать графику уровня плойки 4 минимум. Мне надо чтобы глаза не резало, только и всего. По поводу управления, мне не хватает переходника на type c. У меня джойстик есть от иксбокса360. Потенциала в мобильных играх достаточно чтобы забить кнопки как забивались в той же NFS MW в 2005. Не самая плохая игра была.\n",
            "\n",
            "https: pp.userapi.com c848520 v848520411 11627b cOhWqFbGjWE.jpg\n",
            "\n",
            "Возьмём как пример Россию, западноевропейские страны и США. Идёт метисация, сознательная политика замещения белого населения на пришлое черно-коричневое. Идёт создание новой расы метисов, исламизация и почернение. В крупных городах половина населения - выходцы из ебеней Мексики, Африки, Ближнего Востока, а в случае с Россией - Кавказа и Средней Азии. Этнические ниггеро-арабские гетто верят на хую законы как хотят, чудовищная по масштабам этническая преступность. Говорить о миграции и тем более затрагивать тему замещения коренного населения властями нельзя, иначе бутылка. Свобода слова тут не для вас, молодой человек. При этом говорить о том, что белые должны вымереть, и это нормально - можно. Белые официально вымирают ведётся пропаганда так или иначе направленная на снижение рождаемости белого населения. Феминизм, ЛГБТ, чайлдфри. Каждая женщина в Швеции - леволиберальная феминистка, это страна победившего феминизма. Что сегодня там происходит - страшно делается. Пропагандируются смешанные браки, межрасовые браки, пропагандируется превосходство детей-метисов. Идёт демонизация белых и пропаганда превосходства чёрных и смуглых мужчин, форс отношений белая женщина смуглый чёрный мужчина-мигрант. Как результат - всё больше чернильниц, всё больше смешанных браков, всё больше небелых метисов. Белые женщины просто не хотят контактировать с мужчинами своей нации и расы, наделяя их самыми плохими качествами и обожествляя черных. При этом большинство белых не считает завоз чурок чем-то плохим, наоборот, относятся к ним толерантно. Проводится политика насаждения толерантности, мультикультурализма, политкорректности и космополитизма. Набирающее популярность даже в России SJW - это вообще отдельная тема для обсуждения. Всё вышеперечисленное относится к сильнейшим когда-то странам, бывшим империям, нагибающим слабых. Сегодня происходит так, что бывшие империи в прямом смысле деградируют, вырождаются и вымирают, а место сильнейших когда-то, господствующих народов, занимают те, кого когда-то колонизировали. Во Франции к 2080 уже будут доминировать негры и арабы, в России - кавказцы и выходцы из средней Азии, в Великобритании - индийцы, негры, арабы, пакистанцы, etc. А в маленьких, нейтральных странах, вроде Словении или Беларуси, Литвы или Чехии, Румынии или Эстонии - всё пучком. Им вымирание не грозит, они остаются и будут оставаться белыми. Более того, у них ведётся политика, направленная на сохранение традиционных ценностей и культуры коренного населения. Они сказали беженцам нет . В Польшу, например, русскому или украинцу гораздо легче переехать и остаться, чем арабу или африканцу. В Германии ситуация противоположная, белых там не ждут. Польша, Чехия, Словакия, Венгрия, Словения, Хорватия, Сербия, БиГ, Черногория, Македония, Греция, Болгария, Румыния, Молдова, Украина, Беларусь, Литва, Латвия, Эстония - вот Европа будущего. Скандинавия, Южная, Западная Европа, а также Россия - лишатся коренного населения и своей культуры.\n",
            "\n",
            "Может и старый, может и маразматик. Про то писать кириллицей или латинницей вам виднее, не спорю. Но как задвигают русский язык уже видно. Дальше скажут что все будет только на казахском и внезапно пол страны окажется вторым сортом. (Я надеюсь, что ошибаюсь, но это уже проходили в других странах азии, прибалтики, закавказья) А так я за мир во всем мире. Русский слон лучший друг Казахского слона.\n",
            "\n",
            "Шизофазия (речевая разорванность) симптом психических расстройств, выражающийся в нарушении структуры речи, при которой, в отличие от речевой бессвязности (потока несвязанных слов), фразы строятся правильно 1 , однако не несут никакой смысловой нагрузки, а содержание речи соответствует содержанию бреда 2 . Это расстройство речи отражает разорванность мышления пациентов 3 . Это расстройство характерно прежде всего для шизофрении. Понятие шизофазии было введено Э. Крепелином в 1913 году и некоторое время она считалась особой формой шизофрении 4 . Некоторые авторы даже выделяют отдельную форму шизофрении с таким названием 3 . Для шизофазии характерна повышенная речевая активность, речевой напор, а также симптом монолога , характеризующийся речевой неистощимостью и отсутствием потребности в собеседнике 4 . Как правило, этот симптом сочетается с внешней упорядоченностью, доступностью для общения и относительной интеллектуальной и аффективной сохранностью больных 4 . Отличительной чертой шизофазии считаются преимущественная продукция морфемных словообразований и глоссоманиакальных высказываний 5 . Помимо параноидной формы шизофрении 4 она может возникать при тяжёлом слабоумии 6 .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Dataset is not perfect. It is quite hard to create a flawless model having flawed Dataset."
      ],
      "metadata": {
        "id": "nr6N3AIgjhRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I will use 500 samples to train the model\n",
        "train_df, test_df = train_test_split(df, test_size=500)"
      ],
      "metadata": {
        "id": "ilUCm9BYkG5m"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if test subset consists of 500 samples\n",
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTuQb6TdkcN3",
        "outputId": "99bd7bf0-b11a-4363-fb11-987192f7d868"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of good and toxic comments in the test subset\n",
        "test_df['toxic'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfU7z3rZkvnS",
        "outputId": "05590fdb-b433-4eb3-ed38-d08f8fad0c6f"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    343\n",
              "1    157\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good:toxic ratio is 2.1:1 "
      ],
      "metadata": {
        "id": "Ekwaq8QqlZMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of good and toxic comments in the train subset\n",
        "train_df['toxic'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQiUrNsrlTvF",
        "outputId": "6365e07a-ba98-4f33-f920-5c97f73a4a18"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    9243\n",
              "1    4669\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good:toxic ratio is 1.98:1 "
      ],
      "metadata": {
        "id": "nYkXovttlowV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text preprocessing\n",
        "\n",
        "I will use logistic regression to create model of scikit learn library\n",
        "\n",
        "Dataset prerocessing:\n",
        "1. Tokenization of data (division of Data into a list of sentences)\n",
        "2. Delete punctuation marks (e.g. question marks, commas, etc.) and stop words (insignificant words such as 'and', 'or', 'wow!', etc.) \n",
        "3. Stemming (reducing derivative words to their word stem)\n"
      ],
      "metadata": {
        "id": "f5z18Sqol00i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tokenization"
      ],
      "metadata": {
        "id": "Zqm_ECIdoP3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets the 13th comment\n",
        "sentence_example = df.iloc[13]['comment']\n",
        "print(f'Initial text: {sentence_example}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FntZouZcsDpv",
        "outputId": "0d5f5e9c-8011-4488-9392-37e5edc31754"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial text: Уроды!! у нас в семье 3 поколения там родились\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization using nltk library\n",
        "tokens = word_tokenize(sentence_example, language='russian')\n",
        "print(f'Tokens: {tokens}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqM4jVF0uLVi",
        "outputId": "8f86801b-498e-4d7e-c8ec-f75446083381"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Уроды', '!', '!', 'у', 'нас', 'в', 'семье', '3', 'поколения', 'там', 'родились']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Delete punctuation marks "
      ],
      "metadata": {
        "id": "DLBuu5uxegDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting punctuation marks using punctuation from string module\n",
        "tokens_without_punctuation = [i for i in tokens if i not in string.punctuation]\n",
        "print(f'Tokens without punctuation: {tokens_without_punctuation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUL4SWh0ujiC",
        "outputId": "ecca30ec-8795-463d-d0f3-a538e180eb16"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens without punctuation: ['Уроды', 'у', 'нас', 'в', 'семье', '3', 'поколения', 'там', 'родились']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting stop words from nltk library\n",
        "#russian_stop_words = stopwords.words['russian']\n",
        "russian_stop_words = stopwords.words('russian')\n",
        "print(russian_stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHPJteOlu_Eb",
        "outputId": "fcf54171-c48b-4c17-fb00-e1735629b1f9"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting stop words\n",
        "tokens_without_stopwords_and_punctuation = [i for i in tokens_without_punctuation if i not in russian_stop_words]\n",
        "print(f'Tokens without stopwords and punctuation: {tokens_without_stopwords_and_punctuation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b88W0LQGxVVS",
        "outputId": "d4163a3b-2729-4ee8-f8a3-000e74ec6da3"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens without stopwords and punctuation: ['Уроды', 'семье', '3', 'поколения', 'родились']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Stemming"
      ],
      "metadata": {
        "id": "4VurpBg2emqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming (lowercase and deleting suffixes)\n",
        "snowball = SnowballStemmer(language='russian')\n",
        "stemmed_tokens = [snowball.stem(i) for i in tokens_without_stopwords_and_punctuation]\n",
        "print(f'Tokens after stemming: {stemmed_tokens}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jpWjKhXx9sL",
        "outputId": "d1d91485-8fb7-4dab-8721-1c6a660b21ad"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens after stemming: ['урод', 'сем', '3', 'поколен', 'род']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to apply stemming to every sentence in the Dataset\n",
        "\n",
        "snowball = SnowballStemmer(language='russian')\n",
        "russian_stop_words = stopwords.words('russian')\n",
        "\n",
        "def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\n",
        "  # Tokenizing the Data\n",
        "  tokens = word_tokenize(sentence, language='russian')\n",
        "  # Removing punctuation marks\n",
        "  tokens = [i for i in tokens if i not in string.punctuation]\n",
        "  if remove_stop_words:\n",
        "    tokens = [i for i in tokens if i not in russian_stop_words]\n",
        "  tokens = [snowball.stem(i) for i in tokens]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "SrrP3i6paOFP"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if function works correctly\n",
        "print(f'Tokens after stemming: {tokenize_sentence(sentence_example)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKbQECrlcMd9",
        "outputId": "548295d5-d563-4540-bf39-a4b3b9af2934"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens after stemming: ['урод', 'сем', '3', 'поколен', 'род']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "UugFUOyQeurs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Data into TF-IDF matrix\n",
        "\n",
        "vectorizer = TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))"
      ],
      "metadata": {
        "id": "B1Pm0VQEc5yK"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train stage\n",
        "\n",
        "features = vectorizer.fit_transform(train_df['comment'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mkp5vNBNduVe",
        "outputId": "aa447d36-0687-49c8-e280-8ddfa81cb0ce"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class creation of Logistic Regression\n",
        "model = LogisticRegression(random_state=0)\n",
        "# Train model with features and labels (train_df['toxic'])\n",
        "model.fit(features, train_df['toxic'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "1cphpW-Se9AG",
        "outputId": "107c83c2-d585-4f38-9dc3-bf8b2982b263"
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" checked><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how does the model work\n",
        "model.predict(features[0])"
      ],
      "metadata": {
        "id": "SGb26SJej7sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e256df3a-ecfd-4551-ecad-4ed1eef4710f"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model predicts that the 1st comment is a 'good' one"
      ],
      "metadata": {
        "id": "JB8bF5vmypgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read that 1st comment\n",
        "train_df['comment'].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tOBwcoctze1Z",
        "outputId": "df154ac6-cb25-48b5-a09a-7f8820957dd6"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'На госпочту письмо приходит от ГИБДД или ФССП сразу, как сформировано уведомление. А в личном кабинете госуслуг - после обработки уведомления от тех же ГИБДД и т.д. У меня бывало дня два проходило, пока на госуслугах штраф появится.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the prediction was correct"
      ],
      "metadata": {
        "id": "5YqAtz8O2a4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline receives tuples with the component name and the class \n",
        "model_pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
        "    ('model', LogisticRegression(random_state=0)) \n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "YFN344fd2UOL"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pipeline.fit(train_df['comment'], train_df['toxic'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "bfEUIxuGRKg3",
        "outputId": "79ae892d-7ca2-4964-b76e-2649b8b8c464"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x7fbf3d86c280>)),\n",
              "                ('model', LogisticRegression(random_state=0))])"
            ],
            "text/html": [
              "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86c280&gt;)),\n",
              "                (&#x27;model&#x27;, LogisticRegression(random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86c280&gt;)),\n",
              "                (&#x27;model&#x27;, LogisticRegression(random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86c280&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compose our own 'good' comment to test if the model works correctly\n",
        "test_comment = \"Нормальный ноутбук за приемлемую цену\"\n",
        "\n",
        "model_pipeline.predict([test_comment])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI_ISYOKS2GQ",
        "outputId": "69fc6819-9e83-409f-e7bb-23606b7d4490"
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model predicted that the comment is 'good'. Which is true."
      ],
      "metadata": {
        "id": "PVd6ePhITWA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compose our own 'toxic' comment to test if the model works correctly\n",
        "test_comment = \"Дурацкий ноутбук и продавец дебил\"\n",
        "\n",
        "model_pipeline.predict([test_comment])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nhOgSmhTb2b",
        "outputId": "d773758e-ad60-47b9-8934-9eb2a35688fd"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model predicted that the comment is 'toxic'. That is true."
      ],
      "metadata": {
        "id": "WGwOBoa0TvF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metrics"
      ],
      "metadata": {
        "id": "VG-MgWv-UHJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision\n",
        "precision_score(y_true=test_df['toxic'], y_pred=model_pipeline.predict(test_df['comment']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv7XrwKHUS2g",
        "outputId": "0662fe3a-e526-4896-b2c5-7dd42fb2954e"
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9174311926605505"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision is 0.917 which is lower than our goal of 0.95"
      ],
      "metadata": {
        "id": "rHT_I20TWgGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall\n",
        "recall_score(y_true=test_df['toxic'], y_pred=model_pipeline.predict(test_df['comment']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5cZK1MRWG4A",
        "outputId": "e8c564a0-910d-4365-8b4d-86daca2a0104"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6369426751592356"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can obtain a much better prediction result adjusting the threshold value\n",
        "precision, recall, thresholds = precision_recall_curve(y_true=test_df['toxic'], probas_pred=model_pipeline.predict_proba(test_df['comment'])[:, 1])"
      ],
      "metadata": {
        "id": "mK5Ut4ZeW7Hp"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find indexes > 0.95\n",
        "np.where(precision > 0.95)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C15v7z6lfTvN",
        "outputId": "4aa02372-e973-4b42-95f7-779c21734314"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427,\n",
              "        428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 459,\n",
              "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
              "        475, 476, 477, 478, 479, 490, 491, 492, 493, 494, 495, 496, 497,\n",
              "        498, 499, 500]),)"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With threshold greater than 415 the precision is greater than 0.95"
      ],
      "metadata": {
        "id": "2DCFQzsggD5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds[415]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMA7yFKngYVR",
        "outputId": "768dbda1-8b92-4916-f5bc-cf954d8f2e1e"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6010245351718095"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_true=test_df['toxic'], y_pred=model_pipeline.predict_proba(test_df['comment'])[:, 1] > thresholds[415])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcJswdYjgoex",
        "outputId": "71f9580a-edb2-4f81-e843-ca8fe48706ac"
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9523809523809523"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The precision is now above 0.95"
      ],
      "metadata": {
        "id": "BKJvNhzehIBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_true=test_df['toxic'], y_pred=model_pipeline.predict_proba(test_df['comment'])[:, 1] > thresholds[391])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWWrEHXjhMWk",
        "outputId": "51728480-67a6-497f-c9a6-9d57a5d65006"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6305732484076433"
            ]
          },
          "metadata": {},
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving the model"
      ],
      "metadata": {
        "id": "2nCXf9vbiIwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
        "    ('model',\n",
        "     GridSearchCV(\n",
        "        LogisticRegression(random_state=0),\n",
        "        param_grid={'C': [0.1, 1, 10.]},\n",
        "        cv=3,\n",
        "        verbose=4\n",
        "     )\n",
        "  ) \n",
        "])"
      ],
      "metadata": {
        "id": "A49GOh42iLMy"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_pipeline.fit(train_df['comment'], train_df['toxic'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "uNKEst29jZ_S",
        "outputId": "253c194a-911a-4183-cb31-c43e141a1a55"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "[CV 1/3] END .............................C=0.1;, score=0.683 total time=   0.5s\n",
            "[CV 2/3] END .............................C=0.1;, score=0.687 total time=   0.3s\n",
            "[CV 3/3] END .............................C=0.1;, score=0.689 total time=   0.6s\n",
            "[CV 1/3] END ...............................C=1;, score=0.839 total time=   0.8s\n",
            "[CV 2/3] END ...............................C=1;, score=0.838 total time=   0.6s\n",
            "[CV 3/3] END ...............................C=1;, score=0.837 total time=   1.0s\n",
            "[CV 1/3] END ............................C=10.0;, score=0.867 total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/3] END ............................C=10.0;, score=0.865 total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/3] END ............................C=10.0;, score=0.868 total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x7fbf3d86ce50>)),\n",
              "                ('model',\n",
              "                 GridSearchCV(cv=3,\n",
              "                              estimator=LogisticRegression(random_state=0),\n",
              "                              param_grid={'C': [0.1, 1, 10.0]}, verbose=4))])"
            ],
            "text/html": [
              "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86ce50&gt;)),\n",
              "                (&#x27;model&#x27;,\n",
              "                 GridSearchCV(cv=3,\n",
              "                              estimator=LogisticRegression(random_state=0),\n",
              "                              param_grid={&#x27;C&#x27;: [0.1, 1, 10.0]}, verbose=4))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86ce50&gt;)),\n",
              "                (&#x27;model&#x27;,\n",
              "                 GridSearchCV(cv=3,\n",
              "                              estimator=LogisticRegression(random_state=0),\n",
              "                              param_grid={&#x27;C&#x27;: [0.1, 1, 10.0]}, verbose=4))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86ce50&gt;)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">model: GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=0),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 10.0]}, verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 340
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best score 0.868 is for C=10.0"
      ],
      "metadata": {
        "id": "Wv1rlWXPkl2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pipeline_c10 = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
        "    ('model', LogisticRegression(random_state=0, C=10.)) \n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "2mJ59uNTlR8h"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pipeline_c10.fit(train_df['comment'], train_df['toxic'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "0ZaJR3Tilcf8",
        "outputId": "acd7f0eb-9d75-4629-c738-79a9e31bdfc3"
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x7fbf3d86c790>)),\n",
              "                ('model', LogisticRegression(C=10.0, random_state=0))])"
            ],
            "text/html": [
              "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86c790&gt;)),\n",
              "                (&#x27;model&#x27;, LogisticRegression(C=10.0, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86c790&gt;)),\n",
              "                (&#x27;model&#x27;, LogisticRegression(C=10.0, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function &lt;lambda&gt; at 0x7fbf3d86c790&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10.0, random_state=0)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_c10, recall_c10, thresholds_c10 = precision_recall_curve(y_true=test_df['toxic'], probas_pred=model_pipeline_c10.predict_proba(test_df['comment'])[:, 1])"
      ],
      "metadata": {
        "id": "C8oth142l1PE"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(precision_c10 > 0.95)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j7fwaQTpZDY",
        "outputId": "cada5490-4041-4561-8728-42c3dff64ed2"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422,\n",
              "        423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
              "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
              "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
              "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n",
              "        475, 476, 477, 478, 479, 483, 484, 485, 486, 487, 488, 489, 490,\n",
              "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500]),)"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_score(y_true=test_df['toxic'], y_pred=model_pipeline_c10.predict_proba(test_df['comment'])[:, 1] > thresholds_c10[410])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwO7TKD9pi65",
        "outputId": "8271a2a2-9754-4826-a86c-6305f496bec5"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9550561797752809"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_score(y_true=test_df['toxic'], y_pred=model_pipeline_c10.predict_proba(test_df['comment'])[:, 1] > thresholds_c10[410])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57TxA7ivpjYU",
        "outputId": "8eb97f41-e900-498d-86a4-9e71db771008"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5414012738853503"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result: Now the precision value is greater than 0.95\n",
        "But the previous recall value was better at 0.61. Even though the precision increased, we missed some 'toxic' comments."
      ],
      "metadata": {
        "id": "HyrX-Q7NqaaT"
      }
    }
  ]
}